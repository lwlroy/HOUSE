name: Daily House Crawler

on:
  schedule:
    # 每天台灣時間早上 9:00 執行 (UTC+8, 所以 UTC 時間是 01:00)
    - cron: '0 1 * * *'
  workflow_dispatch: # 允許手動觸發
  push:
    branches: [ main ]  # 當推送到 main 分支時也會觸發（僅用於測試）

jobs:
  crawl-houses:
    runs-on: ubuntu-latest
    permissions:
      actions: read  # 需要讀取 actions 的權限來下載 artifacts
      contents: read
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Download previous day data
      id: download-artifact
      uses: dawidd6/action-download-artifact@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        workflow: daily-crawler.yml
        name: house-data
        path: ./previous_data/
        if_no_artifact_found: ignore
        search_artifacts: true
        skip_unpack: false
      continue-on-error: true
      
    - name: Download previous day data (backup method)
      if: steps.download-artifact.outcome == 'failure'
      run: |
        echo "🔄 嘗試使用 GitHub CLI 下載前一天的 artifacts..."
        
        # 使用 GitHub CLI 列出最近的 workflow runs
        echo "🔍 尋找前一次成功的 workflow run..."
        PREV_RUN_ID=$(gh run list --workflow=daily-crawler.yml --status=success --limit=5 --json databaseId --jq '.[0].databaseId' 2>/dev/null || echo "")
        
        if [ -n "$PREV_RUN_ID" ] && [ "$PREV_RUN_ID" != "null" ]; then
          echo "✅ 找到前一次成功執行: $PREV_RUN_ID"
          
          # 嘗試下載 artifacts
          mkdir -p ./previous_data
          if gh run download $PREV_RUN_ID --name house-data --dir ./previous_data 2>/dev/null; then
            echo "✅ 成功使用 GitHub CLI 下載前一天資料"
            ls -la ./previous_data/
          else
            echo "❌ GitHub CLI 下載失敗"
          fi
        else
          echo "⚠️ 沒有找到前一次成功的 workflow run（可能是首次執行）"
        fi
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      continue-on-error: true
      
    - name: Debug download result
      run: |
        echo "🔍 檢查下載結果和檔案系統狀態："
        echo "📂 當前工作目錄："
        pwd
        ls -la
        echo ""
        echo "🎯 檢查 previous_data 目錄："
        if [ -d "./previous_data" ]; then
          echo "✅ ./previous_data 目錄存在"
          echo "📄 目錄內容："
          ls -la ./previous_data/
          echo ""
          echo "🔍 尋找 JSON 檔案："
          find ./previous_data -name "*.json" -type f 2>/dev/null || echo "❌ 沒有找到 JSON 檔案"
          echo ""
          echo "📊 JSON 檔案詳細資訊："
          find ./previous_data -name "*.json" -type f -exec echo "📋 檔案: {}" \; -exec wc -l {} \; 2>/dev/null || echo "❌ 無法分析 JSON 檔案"
        else
          echo "❌ ./previous_data 目錄不存在"
        fi
    
    - name: Run crawler
      env:
        NOTION_API_TOKEN: ${{ secrets.NOTION_API_TOKEN }}
      run: |
        python simple_luzhou_crawler.py --district all
    
    - name: List current data (for debugging)
      run: |
        if [ -d "./data" ]; then
          echo "📁 Current data generated:"
          ls -la ./data/
        fi
    
    - name: Upload current data as artifact
      uses: actions/upload-artifact@v4
      with:
        name: house-data
        path: ./data/
        retention-days: 3  # 保留 3 天的資料，足夠做前一天比較
    
    - name: Show execution summary
      run: |
        echo "🎉 House crawler execution completed!"
        echo "📊 Check Notion for updated house listings"
        if [ -d "logs" ]; then
          echo "📝 Logs available in logs/ directory"
        fi
