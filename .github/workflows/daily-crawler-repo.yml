name: Daily House Crawler (Repository Storage)

on:
  schedule:
    - cron: '0 1 * * *'  # æ¯å¤©å°ç£æ™‚é–“æ—©ä¸Š 9:00
  workflow_dispatch:

jobs:
  crawl-houses:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # ç²å–å®Œæ•´æ­·å²ï¼ŒåŒ…å«è³‡æ–™æª”æ¡ˆ
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Create data directory
      run: |
        mkdir -p data
        mkdir -p logs
    
    - name: Run crawler
      env:
        NOTION_API_TOKEN: ${{ secrets.NOTION_API_TOKEN }}
      run: |
        python simple_luzhou_crawler.py --district all
    
    - name: Commit and push data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        # æ·»åŠ æ–°çš„è³‡æ–™æª”æ¡ˆ
        git add data/
        git add logs/ || true
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´
        if ! git diff --staged --quiet; then
          git commit -m "ğŸ“Š Daily house data update $(date +%Y-%m-%d)"
          git push
        else
          echo "No changes to commit"
        fi
    
    - name: Clean old data files (keep last 7 days)
      run: |
        # æ¸…ç†è¶…é 7 å¤©çš„è³‡æ–™æª”æ¡ˆ
        find data/ -name "*.json" -type f -mtime +7 -delete || true
        
        # å¦‚æœæœ‰åˆªé™¤æª”æ¡ˆï¼Œæäº¤è®Šæ›´
        if ! git diff --quiet; then
          git add data/
          git commit -m "ğŸ§¹ Clean old data files" || true
          git push || true
        fi
